{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0e3d34",
   "metadata": {},
   "source": [
    "# LLM Engineering\n",
    "\n",
    "Working with the chat completions API provided by OpenAI and Ollama for local access to open source language models.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "This project make use of tools that must be available at the commandline in order to be successful.\n",
    "\n",
    "These tools can be installed via the HomeBrew package manager for MacOS.\n",
    "\n",
    "### UV \n",
    "\n",
    "An extremely fast python package and project management tool to setup dependency and the execution environment.\n",
    "\n",
    "```\n",
    "brew install uv\n",
    "```\n",
    "\n",
    "Once installed, setup this workspace with `uv sync`\n",
    "\n",
    "### Ollama\n",
    "\n",
    "A safe and convenient way to work with open source language models.\n",
    "\n",
    "```\n",
    "brew install ollama\n",
    "```\n",
    "\n",
    "Once installed, Ollama must be started in order to pull models and have the chat completions API interact with it.\n",
    "\n",
    "Start Ollama with `ollama serve` and pull models with `ollama pull {model_name}`\n",
    "\n",
    "A search for models available through Ollama can be found at https://ollama.com/search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83779b",
   "metadata": {},
   "source": [
    "## Chat Completions\n",
    "\n",
    "The chat completions API provided by OpenAI provides a uniformed approach to interacting with various providers; Google, Meta, Anthropic, etc.  For simplicity we'll work with Ollama, by Meta, for it's local execution and ability to pull open source models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df66c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# ollama serve\n",
    "# ollama pull llama3.2:3b\n",
    "\n",
    "# initialize the OpenAI client to point to the local ollama server, no api_key needed\n",
    "openai = OpenAI(base_url = 'http://localhost:11434/v1', api_key = 'ollama')\n",
    "\n",
    "message = \"Hello, world!\"\n",
    "response = openai.chat.completions.create(model = \"llama3.2:3b\", messages = [{\"role\" : \"user\", \"content\" : message}])\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
